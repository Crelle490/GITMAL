COURSE
DEFS 
	[HOMEHTML] https://itundervisning.ase.au.dk/ITMAL_E21/Html
	[HOME]     https://itundervisning.ase.au.dk/ITMAL_E21
	[FIGS]     https://itundervisning.ase.au.dk/ITMAL_E21/Html/Figs
	[HOML]     <span style='font-family: courier new, courier;'>[HOML]</span>
	[GITMAL]   <span style='font-family: courier new, courier;'>[GITMAL]</span>
	[GITHOML]  <span style='font-family: courier new, courier;'>[GITHOML]</span>
	[JPYNB]    <span style='font-family: courier new, courier;'>[JPYNB]</span>
	[OPTIONAL] (OPTIONEL)

	[KURSUSINFORMATION]  <a href='https://brightspace.au.dk/d2l/le/lessons/27524/units/244588'>kursusinformation</a>
	[KURSUSFORKORTELSER] <a href='https://brightspace.au.dk/d2l/le/lessons/27524/topics/254943' rel='noopener' target='_blank'>kursusinformation | kursusforkortelser</a>
	[KURSUSINFOGPU]      <a href='https://brightspace.au.dk/d2l/le/lessons/27524/topics/244596' rel='noopener' target='_blank'>kursusinformation | GPU Cluster</a>

	[SLIDES(arg)]       slide arg

	[BR] <br>

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT Litteratur

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{Litteratur}

\sub{Hands-on Machine Learning [HOML]}

\dl{
	\dd{\img{[FIGS]/book_homl.jpg, Hands-on Machine Learning with Scikit-Learn (front image)}}
	\dd{\i{Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow:[BR] Concepts, Tools, and Techniques to Build Intelligent Systems}}
	\dd{[BR]}
	\dd{Aurélien Géron}
	\dd{O'Reilly / Wiley, 2019, 2.ed.}
	\dd{ISBN: 9781492032649}
	\dd{\link{O'Reilly link,https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/}}
	\dd{[BR]}
	\dl{
		\dt{\i{NOTE 1:}} 
			\dd{Dette er anden udgave (Second Edition/2.ed) af Géron's " Hands-on",	
			undgå at bruge førsteudgaven, idet den benytter TensorFlow direkte istedet for
			Keras, og desuden har flere mangler.}

		\dt{\i{NOTE 2:}}
			\dd{I PDF udgaven (Early Release, June 2019, 2019-04-22: Fifth Release)
			svare sidetal og nogle kaptitler ikke til den officielle bog udgave ovenfor!}
	}
}

\sub{Deep Learning [DL]}

\dl{
	\dd{\img{[FIGS]/book_dl.jpg, Deep Learning (front image)}}
	\dd{\i{Deep Learning}}
	\dd{[BR]}
	\dd{Ian Goodfellow, Yoshua Bengio, Aaron Courville}
	\dd{The MIT Press}
	\dd{November 18, 2016}
	\dd{Hardcover: 775 pages}
	\dd{ISBN-10: 0262035618}
	\dd{ISBN-13: 978-0262035613}
	\dd{\link{http://www.deeplearningbook.org/}}
	\dd{[BR]}
	\dl{
		\dt{\i{NOTE:}}
			\dd{Ikke obligatorisk, kun få afsnit og figure bruges herfra.  
			(Bog god til videregående Neural Netværks-teori
			og meget brugt i ML sammenhænge.)}
	}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT Kursusforkortelser

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{Kursusforkortelser}

\dl{
	\dt{[\b{AI}]:}
	\dd{Artificial intelligence (kunstig intelligens). Generelt bruges udtrykket ML istedet for AI i kurset.}

	\dt{[\b{CNN}]}
	\dd{Convolutional Neural Network(s), undersort at NNs, primært til billebehandling.}

	\dt{[\b{DL}]}
	\dd{Enten bare Deep Learning eller Deep Learning bogen af Ian Goodfellow, et. al.}
				
	\dt{[\b{G}]}
	\dd{Group, ITMAL øvelsesgruppe.}
		
	\dt{[\b{GITHOML}]}
	\dd{
		\dl{
			\dt{GitHub repository til [HOML],}
			\dd{\link{https://github.com/ageron/handson-ml2/}}
			\dt{Clone via HTTPS}
			\dd{\code{git clone https://github.com/ageron/handson-ml2.git}}
			\dt{eller via SSH}
			\dd{\code{git clone git@github.com:ageron/handson-ml2.git}}
		}
	}

	\dt{[\b{GITMAL}]}
	\dd{
		\dl{
			\dt{Git repository for ITMAL,}
			\dd{\link{https://gitlab.au.dk/au204573/GITMAL/}}
			\dt{Clone via HTTPS}
			\dd{\code{git clone https://gitlab.au.dk/au204573/GITMAL.git}}
			\dt{eller via SSH}
			\dd{\code{git clone git@gitlab.au.dk:au204573/GITMAL.git}}
		}
	}

	\dt{[\b{HOML}]}
	\dd{Hands-on Machine Learning af Aurélien Géron, hovedlitteratur til dette kursus. For klarhedens skyld undtales 'HOML' som Holm i Brian Holm.}
	\dd{
		[BR]\img{[FIGS]/brian_holm.jpg, Brian Holm (foto fra cdn-ctstaging.pressidium.com)}
		[BR]\cite{https://cdn-ctstaging.pressidium.com/wp-content/uploads/2020/12/CORVOS_00000365-066.jpg}
	}

	\dt{[\b{ITMAL}]}
	\dd{IT Machine Learning, kursusnavnet.}

	% [J1, J2, .. JN]: En journal opgave/aflevering, f.eks. "Journal 1" (J1). 'Journaler' erstattes af 'opgave afleveringer', O1, O2, osv.

	\dt{[\b{JPYNB}]}
	\dd{Jypyter Python NoteBook, dvs. Notebook applikationen eller en notebook kildetekst fil (med endelsen .ipynb).}

	\dt{[\b{ML}]}
	\dd{Machine Learning, det generelle koncept.}
	
	\dt{[\b{NN}]}
	\dd{Neural Network(s). Normalt forstået som fully-connected neurale netværk (se også CNN).}

	\dt{[\b{O1, O2, O3, O4}]}
	\dd{En opgaveaflevering, f.eks. O1 for opgaveaflevering 1.} %(opgave afleveringer hed tidligere journaler).

	%\dt{[RNN:]}
	%\dd{Recurrent Neural Network(s), undersort at NNs, men med indbygget \i{hukommelse}. }


	\dt{[\b{SG}]}
	\dd{Super-group, bestående af tre eller fire Grupper [G]'s.}

	\dt{[\b{Q}]:}
	\dd{Et specifikt spørgsmål (Question) i en journal opgave, ala Qc for opgave 'c' i et journal spørgsmål.}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT Dokumentation og links

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sub{Web sites}

Primære

\dl{
    \dt{[GITHOML]:}
	    \dd{\link{https://github.com/ageron/handson-ml2/}}
    \dt{Scikit-learn:} 
    	\dd{\link{https://scikit-learn.org/stable/}}
    \dt{Keras:}
    	\dd{\link{https://keras.io/}}
}

Sekundære

\itemize{
    \item{\link{Jupyter: jupyter-notebook.readthedocs.io/en/stable,  https://jupyter-notebook.readthedocs.io/en/stable/}}
    \item{\link{Anaconda Cloud: anaconda.org,                        https://anaconda.org/}}
   	\item{\link{Tensorflow: www.tensorflow.org,                      https://www.tensorflow.org/}}
}

Datakilder

\itemize{
    \item{\link{Kaggle datasets: www.kaggle.com, https://www.kaggle.com/}}
    \item{\i{Sign in with your email} => genbrug gerne min konto, og undgå tidsplid:
    	\itemize{
           \item{user: cef@ase.au.dk}
           \item{password: test123}
        }
	}
}

Dokumentation

\itemize{
    \item{Brug den inbyggede hjælp i [JPYNP]}
    \img{[FIGS]/Screenshot_jupyter_help.png,}
}

Guides etc.

\itemize{
    \item{\link{A Quick Python intro (short),      https://www.w3schools.com/python/python_intro.asp}}
    \item{\link{A Python tutorial (not so short!), https://docs.python.org/3/tutorial/}}
    \item{Jupyter shortcuts quick guide XXX}
    \item{Scikit-learn reference XXX}
    \item{Scikit-learn cheat sheet XXX}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT GPU Cluster

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Der er adgang til en GPU baseret server ifbm kurset. Serveren består af en 'master' som kan tilgås via

\dl{
	\dd{\link{http://gpucluster.st.lab.au.dk/}}
}

og fem 'slave' noder med GPU'er via

\dl{	
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub1}}
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub2}}
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub3}}
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub4}}
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub4}}
	\dd{\link{http://gpucluster.st.lab.au.dk/jhub5} (GPU 3090 og ny 4GHz CPU, 3090 har problemer med Tensorflow)}
}

som frit kan benyttes.

\p{Adgang kræver at i er på EDUROAM eller VPN/au access.}

\p{Der er pt. ingen load-balancing på de fire noder så se på gpucluster hjemmesiden, hvilke noder der er mindst belastede (via TOP
dataen).}

\sub{Brug}

\p{Alle grupper har fået deres egen konto, og f.eks. så logger Grp 09 ind som:}

\dl{
	\dd{Login: f21mal09}
	\dd{Password: f21mal09_123}
}

\p{Dvs. brugernavn/login f21malXX hvor XX er jeres ITMAL gruppe og password sammen som brugernavn med med _123
tilføjet.}

\sub{Quick Guide}

\dl{
	\dt{GIT via Jupyter:}
		\dd{I kan clone git repositoret via en '!'-shell commando i Jupyter notepad'en}
		\dd{\code{! git clone https://cfrigaard@bitbucket.org/cfrigaard/itmal}}
		\dd{og så herefter pull'e via}
		\dd{\code{! cd itmal && git pull}}

	\dt{PYTHONPATH}
		\dd{NOTE: PYTHONPATH er IKKE sat (som vi gjorde i L03/modules_and _classes.ipynb), men kan simuleres via}
		\dd{\code{import sys,os sys.path.append(os.path.expanduser('~/itmal'))}}
}

\p{Hvis du kloner [GITMAL] til itmal som overnfor er der nu automatisk sat en path op til libitaml, prøv det!}

\sub{GPU Hukommelse}

\p{Ved brug af Keras+GPU allokeres automatisk al GPU hukommelse.  Når vi er flere brugere skal i derfor indsætte
følgende i starten af jeres Keras/Tensorflow Jupyternotebook kode:}

	\displaycode{
		import tensorflow as tf
		from keras.backend.tensorflow_backend import set_session
		config = tf.ConfigProto()
		config.gpu_options.per_process_gpu_memory_fraction = 0.05
		config.gpu_options.allow_growth=True
		set_session(tf.Session(config=config))
	}

eller blot

	\displaycode{
		from libitmal import kernelfuns as itmalkernelfuns
		itmalkernelfuns.EnableGPU()
	}

\p{så allokeres kun en brøkdel af GPU hukommelsen! Det ser ud til at growth=True ikke virker, så sæt per_process_gpu_memory_fraction op hvis i har
behov.}

\p{Der kører nu et automatisk startup-script når i logger ind/åbner en nodebook. Se}

	\displaycode{/home/shared/(??)/startup/00_init.py}

\p{der kører StartupSequence_SetPath() og StartupSequence_EnableGPU(), den sidste unktion med følgende default
paramete}

	\displaycode{def StartupSequence_EnableGPU(gpu_mem_fraction=0.05, gpus=None, cpus=None)}

\p{Bemærk at jeres jupyter server, beholder all hukommelse, også når i logger af...kun "stop my server"/"start server"
frigiver!}

%\p{Jeg vil slå alle proceser ned, der har allokeret over ca.  4Gb GPU hukommelse eller har kørt i en uge...det er en
%automatisk process, der kører med ca 5.  interval!}

\sub{Noter}

\p{Terminal på cluster: brug Jupyter notebooks terminalen. Herefter har du en fin terminal på cluster noden}

\p{SSH til cluster: eller gør det på den klassiske metode via SSH til clusterens 'masternode' via}

	\displaycode{> ssh -p 443 gpucluster.st.lab.au.dk}

\p{og herfra videre til 'noder' via ssh node 1 til node 5, f.eks.}

	\displaycode{> ssh node3}

\p{Brug ikke 'masternode'en til udregninger, kun node 1 til 5!}

\p{Sæt gerne jeres SSH certifickater på, så i slipper for login/password.}

\p{Password kan kun ændres via SSH og \code{> passwd}}

\p{Se Hvad der kører på CPU}

	\displaycode{! top -n1}

\p{Se Hvad der kører på GPU}

	\displaycode{! nvidia-smi}

\p{Kill din egne processer}

	\displaycode{! kill -9 <pid>}

\p{eller}

	\displaycode{! pkill <procesnavn>}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT L00

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{Forberedelse inden kursusstart}

\sub{Formål}

\p{\i{Gruppe tilmelding:} tilmeld dig til en ITMAL gruppe (find link i Brightspace!).}

\p{\i{Installation}: de obligatoriske værktøjer til ITMAL inden kursusstart (dvs.
L01).}

\p{\i{Forberedelse til L01:} Hent GIT repositories til litteraturen [GITHOML], prøv at
kører et par Jupyter Notebooks [JPYNB], og læs mere om pythons NumPy
bibliotek.}

\p{\i{Ekstra materiale til forberedelse:} optionelle python opgaver, hvis du vil sætte
dig mere ind i sproget.}

\sub{Installation}

\itemize{
	\item{Installer Anaconda på din PC:}
		\subitem{\link**{www.anaconda.com/products/individual, https://www.anaconda.com/products/individual}}
		\subitem{vælg 'Download' (downloader direkte for Windows),}
		\subitem{eller vælg Linux eller Mac, 32 eller 64 bit (dit valg),} 
		\subitem{nværende nyeste Anaconda3 version er \b{2021.05}}
	\item{ALTERNATIV 1:}
		\subitem{brug vores ASE GPU Cluster som jupyter hub server,}
		\subitem{se info in [KURSUSINFOGPU].}
	\item{ALTERNATIV 2:}
		\subitem{Lav en konto på Google's Colaboratory,}
		\subitem{\link{https://colab.research.google.com}}
	\item{Test at du kan køre jupyter notebooks [JYPYNB] fra [GITHOML], prøv f.eks. \ipynb{index.ipynb}}
}

\sub{Forberedelse til Lektion 01}

\itemize{
	\item{Læs materiale i [KURSUSINFORMATION],}
	\item{få fat i litteratur til kurset,}
	\item{clone [GITHOML] til din egen PC, se how-to under [KURSUSFORKORTELSER].}
	\item{skim denne tutorial igennem:}
	\displaystyle{\em{§ Scientific Python tutorials:} NumPy, \ipynb{tools_numpy.ipynb}, [GITHOML]
		
		[BR][BR]
		
		Læs blot, hvad du finder relevant så som 'iteration', men spring blot over
		emner, der er for komplekse eller for 'pythoniske', så som 'Stacking arrays' og
		'QR decomposition'. 
	}
}

\sub{Note vdr. kildekritik og 'informations-overload'}

\p{Vi vil i dette kurset tit kunne blive overvældet af for meget ekstern
information (informations-overload), så du skal danne dig en metode til at
kunne selektere og navigere i materialet.}

\p{Vi vil primært holde os til [HOML], [GITHOML] og Scikit-learn, med en note
om, at nettet flyder over med ekstra (til tider ubrugelig/ufiltreret)
information: en kildekritiks holdning er vigtig!} 

\sub{Ekstra materiale til forberedelse}

\p{Hvis du har brug for at opfriske dit lineær algebra matematik eller er helt
ny til python, så kan du f.eks.  læse/skimme følgende notebooks, i prioriteret
rækkefølge:}

\enumerate{
	\item{[OPTIONAL] python og vectors/matrices math:            [BR] \indent{\ipynb{math_linear_algebra.ipynb}        [GITHOML],}}
	\item{[OPTIONAL] python og grafisk plotting:                 [BR] \indent{\ipynb{tools_matplotlib.ipynb}           [GITHOML],}}
	\item{[OPTIONAL] ekstra, Python og dataværktøjet 'Pandas':   [BR] \indent{\ipynb{tools_pandas.ipynb}               [GITHOML],}}
	\item{[OPTIONAL] ekstra, mest for de matematik intereserede: [BR] \indent{\ipynb{math_differential_calculus.ipynb} [GITHOML].}}
}

\p{Pandas er et meget populært databehandlingsværktøj, men det
bruges/introduceres dog ikke formelt i dette kursus (du er velkommen til selv
at undersøg/bruge det).}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT L01

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{Introduktion}

\sub{Formål}

Denne lektion har til formål at give indledende information om kurset.  Dvs. 
at vi præsentere de formelle rammer vdr.

\itemize{
	\item{ITMAL gruppetilmelding,}
	\item{opgavesæt og journalafleveringer,}
	\item{eksamensform,}
	\item{Blackboard opbygning og fildeling.}
}

\p{Herefter vil vi præsentere machine learning [ML] som koncept overordnet, og
kort ridse lektionsplanen for kurset op.}

\p{Software til brug for kurset introduceres og skal installeres på jeres PC'er,
se 'L00: Forberedelse' for en installationsguide.  Vi anvender python
distributionen anaconda og i henter og installere den sidste nye version.  På
klassen vil der blive givet en kort demo af jupyter notebooks, dvs.  et at de
udviklingsværktøjer til python vi vil bruge.}

\p{Vi kigge på Scikit-learn, det primære eksterne web-sted vi vil bruge i kurset,
samt forsøge os med et par små programmer i python.}

\p{Til slut kigger vi på supervised learning og at kunne predicte
'life-satisfactory' via demo projektet i [HOML], og vi ser på pythons modul- og
klassebegreber (modules, classes), så vi kan genbruge kode i senere
lektioner..}

\sub{Indhold}

\itemize{
	\item{Formelle rammer vdr. kurset.}
	\item{Eksamensform, godkendelsesfag via:}
	\itemize{
		\item{et sæt obligatoriske skriftlige gruppe-journaler med afleveringsdeadlines,}
		\item{en poster-session, med aflevering af poster og mundtlig præsentation af poster,}
		\item{en mundtlig gennemgang af den sidste journal med alle medlemmer i ITMAL gruppen, samt evaluering af hver gruppemedlems
		bidrag.}
		\displaystyle{\b{\style{color: #ff3333, => Endelig godkendelse af kurset sker på en samlet vurdering af de tre punkter ovenfor.}}}
	}
	\item{Læringsmål.}
	\item{Litteratur.}
	\item{Intro til software, der bruges i ITMAL:}
	\itemize{
		\item{python generelt (link til mini python intro: \link**{[HOME]/L01/demo.ipynb},}
		\item{anaconda python distribution:}
		\itemize{
			\item{jupyter notebooks,}
			\item{spyder developer environment.}
		}
		\item{Scikit-learn,}
		\item{opgave med python modul og klasser.}
	}
	\item{Intro til machine learning:}
	\itemize{
		\item{Supervised learning (regression): 'life-satisfactory' [HOML].}
	}
}

\sub{Litteratur}

	\displaystyle{§ Preface, p. xv [HOML] (eksklusiv fra Using Code Examples...og resten af intro	kapitlet)}
	
	\displaystyle{§ 1 The machine Learning Landscape [HOML]}

	\displaystyle{§ 2 End-to-End Machine Learning Project [HOML]}

\p{Dette kapitel indeholder mange nye koncepter og en del kode.  Vi vender
senere tilbage til kapitlet senere, så læs det og prøv at danne dig et overblik
(dvs. nærlæs ikke).}

\p{Når du har installeret anaconda (se L00):}

	\displaystyle{§ Scientific Python tutorials: NumPy}
	
	\displaystyle{tools_numpy.ipynb [GITHOML]}

\p{Læs blot, hvad du finder relevant så som 'iteration', men spring blot over
emner, der er for komplekse eller for 'pythoniske', så som 'Stacking arrays' og
'QR decomposition'.}

\sub{Forberedelse inden lektionen}

\itemize{
	\item{Meld dig ind i en ITMAL working-group [G].}
	\item{Følg installation processen givet i lektion nul ('L00: Forberedelse').}
	\item{Læs pensum.}
}

\sub{På klassen}

\enumerate{
	\item{Diskussion om ML (indlejret i forelæsningen).}
	\item{\b{Opgave} (introduktion): \link**{[HOME]/L01/intro.ipynb}}
	\subitem*{HUSK DATA til intro'en (download og udpak så "dataset" dir ligger sammen med intro.ipynb): \link**{[HOME]/L01/datasets.zip}}
	\item{\b{Opgave} (python introduktion): \link**{[HOME]/L01/modules_and_classes.ipynb}}
}

\sub{Optionelle opgaver}

\p{Se 'Ekstra materiale til forberedelse' i lektion 'nul', specielt hvis du har
brug for en python og lineær algebra kick-start.}

\sub{Slides}

\displaystyle{
	\link**{[HOME]/L01/lesson01.pdf}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT L02

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{Supervised classification, Cost function, Performance metrics}

\sub{Formål}

\p{Vi lægger ud med at se på datamat-læring eller ML-læring via cost
funktionen, J, dvs.  hvordan en supervised ML algoritme i princippet kunne
tænkes at fungere.  Til cost funktionen tager vi hul på et par grundliggende
lineær algebra koncepter: "norm" eller afstandsmål mellem to N-dimensionale
vektorer, og vi ser hvordan Mean-Square-Error (MSE) og Mean-Absolute-Error
(MAE) kunne indgå i J.}

\p{Herefter studerer vi begrebet supervised klassifikation dybere og bruger
Scikit-learns fit-predict interface til konkret at lave og køre ML-kode.  Vi
går i detaljen med den fundamentale train/test-split og fit/predict proces vdr. 
supervised learning, og vi bruger diverse kendte små dataset, som vi også vil
benytte i resten af kurset: MNIST, Iris og Moon.}

\p{Til sidst evaluere vi en kørt ML læring ved brug af diverse performance
metrics, dvs.  metoder til generelt at kvantificere hvor 'god' (kvalitet) en
læring den pågældende algoritme har opnået på de pågældende data.}

\sub{Indhold}

\itemize{
	\item{Lineær algebra og cost funktionen, J}
	\itemize{
		\item{matricer, vektors, norms og NumPy,}
		\item{MSE, MAE,
		\item{ML læring via J}
	}
	\item{Klassifikation}
        \itemize{
	        \item{’demo’ datasæt:  MNIST, iris and moon}
    	    \item{fundamental ML supervised lærings-proces,}
       		\enumerate{
           		 \item{forbered data: shuffle, stratification, normalization}
           		 \item{train/test split}
           		 \item{træn på træningsdata}
           		 \item{evaluer på test data:  performance metrics}
			}
		}
    \item{Performance metrics}
    	\itemize{
        	\item{the accuracy paradox,}
        	\item{vigtige metrics,}
			\itemize{
				\item{accuracy}
				\item{precision_score}
				\item{recall_score}
				\item{f1_score}
				\item{confusion_matrix}
			}
		}
	}
}

\sub{Litteratur}

\displaystyle{
	\i{§ 2 "End-to-End Machine Learning Project"} kapitel \i{"Select a
	Performance Measure"}, [HOML]

	[BR] Genlæs KUN "Select a Performance Measure" (pp.39-41)
}
\displaystyle{
	\i{§ 3 Classification} [HOML]}

	[BR] Skim eller spring over: \i{"The ROC Curve"} (pp.97-1o0) \i{"Multilabel
	Classification"} og \i{"Multioutput Classification"} (pp.106-108).
}

\sub{Forberedelse inden lektionen}

\itemize{
	\item{Læs litteraturen.}
}

\sub{På klassen}

\enumerate{
	\item{Almindelig forelæsning}
	\item{\b{Opgave} (cost funktionen og lineær algebra):             \link**{[HOME]/L02/cost_function.ipynb}}
	\item{\b{Opgave} (supervised learning og fit-predict interfacet): \link**{[HOME]/L02/dummy_classifier.ipynb}}
	\item{\b{Opgave} (performace metrikker):                          \link**{[HOME]/L02/performance_metrics.ipynb}}
}

\sub{Slides}

\displaystyle{
	\link**{[HOME]/L02/lesson02.pdf}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

CONTENT L03 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\header{End-to-end ML}

\sub{Formål}

\p{Opsamlingslektion: vi tager et genblik på \i{§ 2 "End-to-End Machine Learning Project"}, og samler op på dette brede
kapitel.}

\p{Vi går først igang med at gennemgå \i{K-fold Cross-validation} (eller K-fold CV), for derefter at bruge \link{"The
Map", [HOME]/Etc/ml_supervised_map.pdf} til at komme igennem alle grundliggende koncepter i \i{§ 2}.}

\p{Da alle kerne-koncepter i supervised ML nu kendes, kan det hele konkret sammensættes i en samlet
processerings-\i{pipeline}.  Programmerings-teknisk ser vi derfor til sidst på Scikit-learns Pipelines.}

\displaystyle{
	\link{\img{[FIGS]/ml_supervised_map.png, Supervised map image.}, [HOME]/Etc/ml_supervised_map.pdf}
	[BR] \i{Figur: \link*{Oversigtskortet for Supervised learning.,  [HOME]/Etc/ml_supervised_map.pdf}}
}

\sub{Indhold}

\itemize{
	\item{Generel genlæsning og repetition af § 2}
	\item{K-fold Cross-validation}
	\item{Pipelines}
}

\sub{Litteratur}

\enumerate{
	\item{Genlæs: § 2 "End-to-End Machine Learning Project" [HOML]}
		\subitem*{(eksklusiv "Create the Workspace" og "Download the Data")}
	\item{Scikit's dokumentations-side vdr. k-fold CV}
		\subitem*{\link{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html}}
}

\sub{Forberedelse inden lektionen} 

\itemize{
	\item{Læs litteraturen.}
}

\sub{På klassen}

\itemize{
    \item{Almindelig forelæsning}
		\subitem*{ekstra materiale: \link**{[HOME]/L03/Extra/k-fold_demo.ipynb}}
    \item{\b{Opgave} (pipelines): \link**{[HOME]/L03/pipelines.ipynb}}
   		\subitem*{Data til pipelines opgaven (bør lige i L03/Data/): \link**{[HOME]/L03/itmal_l01_data.pkl}}
		\subitem*{(Du har allerede denne data-fil, hvis du pull'er fra [GITMAL])}
}

\sub{Slides}

\displaystyle{
	\link**{[HOME]/L03/lesson03.pdf}
}

END
